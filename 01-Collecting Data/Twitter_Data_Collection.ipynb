{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b21acc1",
   "metadata": {},
   "source": [
    "In this notebook, we are going to collect our data from Twitter. For this, you need to have fristly created a twitter developer account and after that, made an API which gives you keys for connecting. \n",
    "If you don't know how to do so, please follow this link.\n",
    "When you create the API for your software, in your developer portal at Twitter website, you'll be able to reach the data details of your API including: API Key, API Key Secret, and Bearer Token\n",
    "Next, you need to have some packages installed that you can gather data and from Twitter and do analysis on this data. In this notebook, we would describe and install all of these packages (if required), so, you won't need to install them for the next steps of the project.\n",
    "\n",
    "The list of these packages are as follow:\n",
    "* tweepy\n",
    "* nlkt\n",
    "* textblob\n",
    "* collections\n",
    "* matplotlib\n",
    "* json\n",
    "* pandas\n",
    "* numpy\n",
    "* pickle\n",
    "* datatime\n",
    "* pprint\n",
    "* WordCloud\n",
    "\n",
    "As mentioned-above, all of these packages are required for this project. However, for this file which is the first step, we would need only sum of them. So, we need to install them and use anything related which is required.\n",
    "For the very first step, we need to install the packages for collecting data from Twitter. This package is tweepy.\n",
    "\n",
    "Tweepy (https://www.tweepy.org/), is an easy-to-use Python library for assessing the Twitter API. To install we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48232220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /opt/anaconda3/lib/python3.9/site-packages (4.10.1)\r\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in /opt/anaconda3/lib/python3.9/site-packages (from tweepy) (3.2.1)\r\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in /opt/anaconda3/lib/python3.9/site-packages (from tweepy) (2.27.1)\r\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /opt/anaconda3/lib/python3.9/site-packages (from tweepy) (1.3.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (2021.10.8)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (3.3)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (2.0.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (1.26.9)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e236e5ae",
   "metadata": {},
   "source": [
    "The next step is to gather data using this package and the API, you've made. So, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33a2f827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3676108e",
   "metadata": {},
   "source": [
    "Pay attention that for collecting data, we need a class made based on the tweepy.\n",
    "This class has a name TwitterCollector. You would need to have the file of related to code of this class, in the place that you have this notebook. Then, you would be able to run the code. As soon as you upload this file, you need the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8df0da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TwitterCollector import TwitterCollector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef284c80",
   "metadata": {},
   "source": [
    "Moreover, as you are going to run functions that will collect data for a period of specific time, you'll ask them, you need another python package related to time and data. Most probably, you've installed it formerly. So, you should go for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "265427c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a27d549",
   "metadata": {},
   "source": [
    "Now, it is time to collect your data. You need your bearer_token and also an initialization for twitter_collector. \n",
    "Pay attention, 'bearer_token' should be the thing you've received from your tweeter developer account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7166dc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bearer_token= r\"AAAAAAAAAAAAAAAAAAAAAN7xhgEAAAAA5mDxdSxnPsiFrmzQ4R2Fvet71Qs%3DeAlmpOrJCjfAhrqhwnnbuZytWstuT1qdXZFLwPE6OZTo6ka2A6\"\n",
    "#initialize it:\n",
    "tc= TwitterCollector(bearer_token=bearer_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf59354",
   "metadata": {},
   "source": [
    "Now, you are prepared to collect data. Just you need to tell about the queries you need. In this project, we are going to go for the word \"Mahsa Amini\", which is one of the greatest trends in Twitter till the end of September 2022.\n",
    "The thing is that, we don't want retweets to be counted again. And we are just considering English Tweets not, Persian. Although the majority of tweets are in English.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2d7734a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1= 'Mahsa Amini -is:retweet lang:en'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbe16f7",
   "metadata": {},
   "source": [
    "For collecting tweets, we have a function fetch_recent_tweets that the inputs include query, the number of tweets we want, and saving the results or not. So, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7f2be6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_tweets_ma= tc.fetch_recent_tweets(query=query1, tweets_cnt=10000, save_result=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c939d7c7",
   "metadata": {},
   "source": [
    "When you run this code, a json file will be created in the folder that you are running the code. You need this file for the next steps to do text mining.\n",
    "\n",
    "Before going for text mining, we can have a better look on the data we collected in recent_tweets_ma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "89033dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(recent_tweets_ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "198761a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['collection_type', 'collection_timestamp', 'query', 'tweet_cnt', 'tweets'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recent_tweets_ma.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e115b2",
   "metadata": {},
   "source": [
    "We see that we have a dictionary with 5 different keys. The last key is 'tweets' which includes more data about a tweet. Let's have a look on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "abe53767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(recent_tweets_ma['tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2bcd7943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(recent_tweets_ma['tweets'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7069b70",
   "metadata": {},
   "source": [
    "So, we can see that 'tweet' is a list of dictionaries. Actually it includes all of our 10000 tweets and each member of this list is a dictionary which includes detail of each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2c6c19e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['entities', 'public_metrics', 'in_reply_to_user_id', 'possibly_sensitive', 'source', 'text', 'id', 'context_annotations', 'lang', 'author_id', 'referenced_tweets', 'created_at', 'edit_history_tweet_ids'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recent_tweets_ma['tweets'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e01398",
   "metadata": {},
   "source": [
    "The information about each tweet are the keys printed from the last line code. Again, each of these keys maybe another dictionary.\n",
    "Indeed, the json file we get from this twitter api is a dictionary of dictionary of ... of dictionaries.\n",
    "\n",
    "We can go further and do more with data to be familiar with. For example, we can get the unique author IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a2869578",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_author_id=[]\n",
    "for tweet in recent_tweets_ma['tweets']:\n",
    "    if tweet['author_id'] not in uniq_author_id:\n",
    "        uniq_author_id.append(tweet['author_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f7e54877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "3306\n"
     ]
    }
   ],
   "source": [
    "print(type(uniq_author_id))\n",
    "print(len(uniq_author_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cabd8b",
   "metadata": {},
   "source": [
    "As we see, we have 3306 unique author id. It means that the 10000 tweets that we've collected are made by 3306 different authors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54ac1dd",
   "metadata": {},
   "source": [
    "We may need to collect more data about this authors using their ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8935c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
